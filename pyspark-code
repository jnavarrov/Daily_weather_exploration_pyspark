# coding: utf-8

# keep in mind SQLContext is a function from pyspark
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

# Change fale path to work
#df is a variable that storage the file i'm working with

df = sqlContext.read.load('file:///home/cloudera/Downloads/big-data-4/daily_weather.csv', 
format='com.databricks.spark.csv',
header='true',inferSchema ='true')

df.columns
df.printSchema()
df.describe()
df.describe().toPandas().transpose()
df.describe('air_pressure_9am').show()

len(df.columns)

df.count()

#Drop NA  Values from air pressure 9am
df2 = df.na.drop(subset=['air_pressure_9am'])
df2.count()

# Correlation between Rain accumulation vs Rain Duration 9am
df2.stat.corr("rain_accumulation_9am","rain_duration_9am")

df.describe('avg_wind_speed_9am').show()
df.columns

#Drop NA  Values from air rain accumulation 9am
df2 = df.na.drop(subset=['rain_accumulation_9am'])
df2.count()

# Correlation between relative humidity 9am n vs relative humidity 3pm
df2.stat.corr("relative_humidity_9am", "relative_humidity_3pm")
df.describe("max_wind_direction_9am","max_wind_speed_9am").show()
df.describe("avg_wind_speed_9am").show()
